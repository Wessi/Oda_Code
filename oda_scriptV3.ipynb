{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of updated projects of both sheets since and before (by donor agency and by SWG)(The number of updated projects refers to both the online Excel sheet and Google form)\n",
    "2. Number of updated projects on the online Excel sheet only (whose online form is not updated)( by donor agency and by SWG)\n",
    "3. Number of new projects and list registered ( by donor agency and by SWG)\n",
    "4. Number of not updated projects ( by donor agency and by SWG)\n",
    "5. Can we get an Excel sheet under each SWG updated and not updated project info of both online and Excel sheet, updated fields colored?\n",
    "6. Can we get all SWG info in one file in the above similar request?\n",
    "\n",
    "On the AMP system or new system or online form: create a links for the user like existing since, existing before, new project, select donor org (select yours in the case of multi), etc. when all infor filled filter out specific project and take the data encoder to relevant page, meaning page with filtered out projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:53: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:53: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\wesag\\AppData\\Local\\Temp\\ipykernel_22124\\3595527233.py:53: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif pd.isna(latest_id) or latest_id.isspace() or bool(re.search(r'[^a-zA-Z0-9\\-]', latest_id)) or latest_id is '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Empty Sheet New Projs Since 2017 has been excluded ######\n",
      "###### Empty Sheet New Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet Deleted Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet New Projs new has been excluded ######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:10<00:04,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Empty Sheet New Projs Since 2017 has been excluded ######\n",
      "###### Empty Sheet Deleted Projs Since 2017 has been excluded ######\n",
      "###### Empty Sheet New Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet Deleted Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet Updated Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet New Projs new has been excluded ######\n",
      "###### Empty Sheet New Projs Since 2017 has been excluded ######\n",
      "###### Empty Sheet Deleted Projs Since 2017 has been excluded ######\n",
      "###### Empty Sheet New Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet Deleted Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet Updated Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet New Projs new has been excluded ######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:17<00:00,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from openpyxl.styles import PatternFill, Border, Side, Alignment, Font\n",
    "# improt tqdm for progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define your functions get_ids_and_titles and compare_stat here\n",
    "# get_ids_and_titles\n",
    "def get_ids_and_titles(original, latest):\n",
    "    # Retrieve values from specific columns\n",
    "    original_titles = original.iloc[7:, 2].values\n",
    "    latest_titles = latest.iloc[7:, 2].values\n",
    "    original_ids = original.iloc[7:, 7].values\n",
    "    latest_ids = latest.iloc[7:, 7].values\n",
    "\n",
    "    return original_titles, latest_titles, original_ids, latest_ids   \n",
    "\n",
    "# compare_stat\n",
    "def compare_stat(original, latest):\n",
    "    # 3. Create dictionaries for categorizing projects\n",
    "    new_projs = {}\n",
    "    original_not_updated_projs = {}\n",
    "    original_updated_projs = {}\n",
    "    deleted_projs = {}\n",
    "\n",
    "    _, latest_titles, original_ids, latest_ids = get_ids_and_titles(original, latest)\n",
    "\n",
    "    # get all ids which are in original but not in latest\n",
    "    for i, original_id in enumerate(original_ids):\n",
    "        if original_id not in latest_ids:\n",
    "            deleted_projs[original_id] = original.iloc[i + 7]\n",
    "\n",
    "    # 4. Iterate over latest IDs for comparison\n",
    "    for i, latest_id in enumerate(latest_ids): \n",
    "        # declare empty index and row variables   \n",
    "\n",
    "        if latest_id in original_ids:\n",
    "            # Find the index of the row with the matching ID in original DataFrame\n",
    "            original_index = original[original.iloc[:, 7] == latest_id].index[0]\n",
    "            original_row = original.iloc[original_index]\n",
    "\n",
    "            # Extract and compare the entire rows\n",
    "            latest_index = latest[latest.iloc[:, 7] == latest_id].index[0]\n",
    "            latest_row = latest.iloc[latest_index]\n",
    "\n",
    "            # Categorize based on comparison\n",
    "            if original_row.equals(latest_row):\n",
    "                original_not_updated_projs[latest_id] = original_row\n",
    "            else:\n",
    "                original_updated_projs[latest_id] = latest_row\n",
    "\n",
    "        # enter here if id null or space or special characters in the ids excluding hyphen '-', id not in 87... or new-... or empty\n",
    "        elif pd.isna(latest_id) or latest_id.isspace() or bool(re.search(r'[^a-zA-Z0-9\\-]', latest_id)) or latest_id is '':\n",
    "            if latest_titles[i] not in new_projs: # latest_titles[i] not in new_project\n",
    "                # new_project as id: corresponding row including values of all columns\n",
    "                new_projs[latest_titles[i]] = latest.iloc[i + 7]\n",
    "            new_projs[latest_titles[i]] = latest.iloc[i + 7]\n",
    "        else:\n",
    "            # print id and say id error\n",
    "            print(f'###### ID ERROR. Id: {latest_id} Title: {latest_titles[i]} ######')                       \n",
    "\n",
    "    return new_projs, deleted_projs, original_not_updated_projs, original_updated_projs\n",
    "\n",
    "def process_files(orig_file, lat_file, output_fname):\n",
    "    original_sinc = pd.read_excel(orig_file, sheet_name=sincesht)\n",
    "    latest_sinc = pd.read_excel(lat_file, sheet_name=sincesht)\n",
    "\n",
    "    original_befo = pd.read_excel(orig_file, sheet_name=beforesht)\n",
    "    latest_befo = pd.read_excel(lat_file, sheet_name=beforesht)\n",
    "\n",
    "    original_new = pd.read_excel(orig_file, sheet_name=newsht)\n",
    "    latest_new = pd.read_excel(lat_file, sheet_name=newsht)\n",
    "\n",
    "    # get comparison statistics\n",
    "    new_project_sinc, deleted_project_sinc, original_not_updated_projs_sinc, original_updated_projs_sinc = compare_stat(original_sinc, latest_sinc)\n",
    "    new_project_befo, deleted_project_befo, original_not_updated_projs_befo, original_updated_projs_befo = compare_stat(original_befo, latest_befo)\n",
    "    new_project_new, deleted_project_new, original_not_updated_projs_new, original_updated_projs_new = compare_stat(original_new, latest_new)\n",
    "\n",
    "    \n",
    "    # write to excel\n",
    "    with pd.ExcelWriter(output_fname) as writer:\n",
    "        pd.DataFrame.from_dict(new_project_sinc, orient='index').to_excel(writer, sheet_name='New Projs Since 2017')\n",
    "        pd.DataFrame.from_dict(deleted_project_sinc, orient='index').to_excel(writer, sheet_name='Deleted Projs Since 2017')\n",
    "        pd.DataFrame.from_dict(original_updated_projs_sinc, orient='index').to_excel(writer, sheet_name='Updated Projs Since 2017')\n",
    "        pd.DataFrame.from_dict(original_not_updated_projs_sinc, orient='index').to_excel(writer, sheet_name='Not Updated Projs Since 2017')\n",
    "\n",
    "        pd.DataFrame.from_dict(new_project_befo, orient='index').to_excel(writer, sheet_name='New Projs Before 2017')\n",
    "        pd.DataFrame.from_dict(deleted_project_befo, orient='index').to_excel(writer, sheet_name='Deleted Projs Before 2017')\n",
    "        pd.DataFrame.from_dict(original_updated_projs_befo, orient='index').to_excel(writer, sheet_name='Updated Projs Before 2017')\n",
    "        pd.DataFrame.from_dict(original_not_updated_projs_befo, orient='index').to_excel(writer, sheet_name='Not Updated Projs Before 2017')\n",
    "\n",
    "        pd.DataFrame.from_dict(new_project_new, orient='index').to_excel(writer, sheet_name='New Projs new')\n",
    "        # pd.DataFrame.from_dict(deleted_project_new, orient='index').to_excel(writer, sheet_name='Deleted Projs new')\n",
    "        # pd.DataFrame.from_dict(original_updated_projs_new, orient='index').to_excel(writer, sheet_name='Updated Projs new')\n",
    "        # pd.DataFrame.from_dict(original_not_updated_projs_new, orient='index').to_excel(writer, sheet_name='Not Updated Projs new')\n",
    "        \n",
    "    # read excel file back and change the column names for all sheets\n",
    "    df = pd.read_excel(output_fname, sheet_name=None)\n",
    "\n",
    "    sheets_to_exclude = []\n",
    "    for sheet in df:\n",
    "        # Check if the sheet has zero columns before slicing\n",
    "        if df[sheet].shape[1] == 0:\n",
    "            sheets_to_exclude.append(sheet)\n",
    "            continue\n",
    "\n",
    "        # Now safe to remove the first two and the last one columns\n",
    "        df[sheet] = df[sheet].iloc[:, 2:-1]\n",
    "\n",
    "        # Further checks and adjustments\n",
    "        if df[sheet].shape[1] > len(cols):\n",
    "            # Slice to only the first 19 columns if there are more\n",
    "            df[sheet] = df[sheet].iloc[:, :len(cols)]\n",
    "        elif df[sheet].shape[1] < len(cols):\n",
    "            # Add missing columns if the DataFrame has fewer than 19 columns\n",
    "            for col in cols[df[sheet].shape[1]:]:\n",
    "                df[sheet][col] = pd.NA\n",
    "\n",
    "        df[sheet].columns = cols\n",
    "\n",
    "    # Concatenate specific sheets into one DataFrame\n",
    "    sheets_to_merge = ['New Projs Since 2017', 'New Projs Before 2017', 'New Projs new']\n",
    "    merged_df = pd.concat([df[s] for s in sheets_to_merge if s not in sheets_to_exclude], axis=0)\n",
    "    df['New Projects'] = merged_df[cols]\n",
    "\n",
    "    # Exclude original sheets that were merged\n",
    "    sheets_to_exclude.extend(sheets_to_merge)\n",
    "\n",
    "    # write to excel\n",
    "    with pd.ExcelWriter(output_fname) as writer:\n",
    "        for sheet in df:\n",
    "            if sheet in sheets_to_exclude:\n",
    "                print(f'###### Empty Sheet {sheet} has been excluded ######')\n",
    "                continue\n",
    "            df[sheet].to_excel(writer, sheet_name=sheet, index=False)\n",
    "            # Access the workbook and the sheet\n",
    "            \n",
    "            worksheet = writer.sheets[sheet]\n",
    "\n",
    "            # highlight the header cells\n",
    "            # Define header format\n",
    "            header_fill = PatternFill(start_color=\"D7E4BC\", end_color=\"D7E4BC\", fill_type=\"solid\")\n",
    "            thin_border = Border(left=Side(style='thin'), \n",
    "                                right=Side(style='thin'), \n",
    "                                top=Side(style='thin'), \n",
    "                                bottom=Side(style='thin'))\n",
    "            header_font = Font(bold=True)\n",
    "            header_alignment = Alignment(horizontal='center', vertical='top', wrap_text=True)\n",
    "\n",
    "            # Apply header format\n",
    "            for cell in worksheet[1]:\n",
    "                cell.fill = header_fill\n",
    "                cell.border = thin_border\n",
    "                cell.font = header_font\n",
    "                cell.alignment = header_alignment\n",
    "\n",
    "            # add filter to the header\n",
    "            worksheet.auto_filter.ref = \"A1:S1\"\n",
    "\n",
    "            # freeze the first row\n",
    "            worksheet.freeze_panes = 'A2' \n",
    "\n",
    "            # Set column widths\n",
    "            high = ['A', 'B']  \n",
    "            medium = ['F', 'G', 'H', 'L', 'M', 'K',  'I', 'J', 'Q', 'R', 'S', 'T'] \n",
    "            low = ['C', 'D', 'E', 'N', 'O', 'P']\n",
    "\n",
    "            for col in high:\n",
    "                worksheet.column_dimensions[col].width = 30\n",
    "\n",
    "            for col in medium:\n",
    "                worksheet.column_dimensions[col].width = 18 \n",
    "\n",
    "            for col in low:\n",
    "                worksheet.column_dimensions[col].width = 12    \n",
    "\n",
    "# Define column names and sheet names\n",
    "cols = ['SWG', 'Project Title', 'Status', 'On/Off/Treasury Budget', 'Humanitarian Aid', 'Project description', \n",
    "        'Project ID (in AMP)', 'Actual Approval Date', 'Actual Start Date', 'Actual Closure Date', \n",
    "        'Donor Group', 'Donor Agency', 'Implementing Agency', 'Type of Assistance', 'Mode of Payment', \n",
    "        'Aid Modality', 'Actual Commitments', 'Actual Disbursements', 'Undisbursed Balance']\n",
    "\n",
    "sincesht = 'Existing projects approved sinc'\n",
    "beforesht = 'Existing projects approved befo'\n",
    "newsht = 'Record new projects'\n",
    "\n",
    "# List of file pairs and their corresponding output files\n",
    "file_pairs = [\n",
    "    ('ODA_Original_and_Latest/OrigHPN.xlsx', 'ODA_Original_and_Latest/LatHPN.xlsx', 'Report/HPN.xlsx'),\n",
    "    ('ODA_Original_and_Latest/OrigBSD.xlsx', 'ODA_Original_and_Latest/LatBSD.xlsx', 'Report/BSD.xlsx'),\n",
    "    ('ODA_Original_and_Latest/OrigREDFS.xlsx', 'ODA_Original_and_Latest/LatREDFS.xlsx', 'Report/REDFS.xlsx'),\n",
    "    # Add more file pairs as needed\n",
    "]\n",
    "\n",
    "tqdm.write('Processing files...')\n",
    "for orig_file, lat_file, output_fname in tqdm(file_pairs):\n",
    "    process_files(orig_file, lat_file, output_fname)\n",
    "tqdm.write('Done!')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all Excel files in a directory into one\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Directory containing Excel files\n",
    "directory = 'Report'\n",
    "\n",
    "# Find all Excel files in the directory\n",
    "excel_files = glob(os.path.join(directory, '*.xlsx'))\n",
    "\n",
    "# Dictionary to store data from each sheet\n",
    "merged_data = {}\n",
    "\n",
    "# Process each file\n",
    "for file in excel_files:\n",
    "    # Read each sheet in the file\n",
    "    xls = pd.ExcelFile(file)\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        # Read the sheet\n",
    "        df = pd.read_excel(file, sheet_name=sheet_name)\n",
    "        \n",
    "        # If the sheet name is already in merged_data, append the new data\n",
    "        if sheet_name in merged_data:\n",
    "            merged_data[sheet_name] = pd.concat([merged_data[sheet_name], df])\n",
    "        else:\n",
    "            merged_data[sheet_name] = df\n",
    "\n",
    "# Write merged data to a new Excel file\n",
    "with pd.ExcelWriter('Merged.xlsx') as writer:\n",
    "    for sheet_name, data in merged_data.items():\n",
    "        data.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tabular\n",
    "# import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "\n",
    "# # Load the Excel file\n",
    "# df = pd.read_excel('Report/HPN.xlsx', sheet_name=None)\n",
    "\n",
    "# # Loop through each sheet and print a tabular summary for column L\n",
    "# for sheet_name, sheet_data in df.items():\n",
    "#     if sheet_data.shape[1] == 0:\n",
    "#         print(f'###### Empty Sheet {sheet_name} has been excluded ######\\n')\n",
    "#         continue\n",
    "\n",
    "#     # Check if column L exists and get its name\n",
    "#     column_L_index = 11  # Index of column L\n",
    "#     if column_L_index < len(sheet_data.columns):\n",
    "#         column_L_name = sheet_data.columns[column_L_index]\n",
    "\n",
    "#         # Group by column L and count the occurrences\n",
    "#         category_counts = sheet_data.groupby(sheet_data[column_L_name]).size()\n",
    "\n",
    "#         # Convert to DataFrame for tabulate\n",
    "#         category_counts_df = category_counts.reset_index()\n",
    "#         category_counts_df.columns = [column_L_name, 'Count']\n",
    "\n",
    "#         # Printing the counts in tabular format\n",
    "#         print(f\"Distribution in {sheet_name} by {column_L_name}:\")\n",
    "#         print(tabulate(category_counts_df, headers='keys', tablefmt='grid'), \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
