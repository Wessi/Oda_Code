{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of updated projects of both sheets since and before (by donor agency and by SWG)(The number of updated projects refers to both the online Excel sheet and Google form)\n",
    "2. Number of updated projects on the online Excel sheet only (whose online form is not updated)( by donor agency and by SWG)\n",
    "3. Number of new projects and list registered ( by donor agency and by SWG)\n",
    "4. Number of not updated projects ( by donor agency and by SWG)\n",
    "5. Can we get an Excel sheet under each SWG updated and not updated project info of both online and Excel sheet, updated fields colored?\n",
    "6. Can we get all SWG info in one file in the above similar request?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Empty Sheet New Projs Since 2017 has been excluded ######\n",
      "###### Empty Sheet New Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet Deleted Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet New Projs new has been excluded ######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:15<00:07,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Empty Sheet New Projs Since 2017 has been excluded ######\n",
      "###### Empty Sheet Deleted Projs Since 2017 has been excluded ######\n",
      "###### Empty Sheet New Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet Deleted Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet Updated Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet New Projs new has been excluded ######\n",
      "###### Empty Sheet New Projs Since 2017 has been excluded ######\n",
      "###### Empty Sheet Deleted Projs Since 2017 has been excluded ######\n",
      "###### Empty Sheet New Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet Deleted Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet Updated Projs Before 2017 has been excluded ######\n",
      "###### Empty Sheet New Projs new has been excluded ######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Found 61 matching rows in Updated Projs Since 2017\n",
      "Found 18 matching rows in Not Updated Projs Since 2017\n",
      "Found 118 matching rows in New Projects\n",
      "Found 27 matching rows in Updated Projs Before 2017\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from openpyxl.styles import PatternFill, Border, Side, Alignment, Font\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "def format_excel(writer, sheet_name):\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    header_fill = PatternFill(start_color=\"D7E4BC\", end_color=\"D7E4BC\", fill_type=\"solid\")\n",
    "    thin_border = Border(left=Side(style='thin'), \n",
    "                        right=Side(style='thin'), \n",
    "                        top=Side(style='thin'), \n",
    "                        bottom=Side(style='thin'))\n",
    "    header_font = Font(bold=True)\n",
    "    header_alignment = Alignment(horizontal='center', vertical='top', wrap_text=True)\n",
    "\n",
    "    for cell in worksheet[1]:\n",
    "        cell.fill = header_fill\n",
    "        cell.border = thin_border\n",
    "        cell.font = header_font\n",
    "        cell.alignment = header_alignment\n",
    "\n",
    "    worksheet.auto_filter.ref = \"A1:S1\"\n",
    "    worksheet.freeze_panes = 'A2' \n",
    "\n",
    "    high = ['A', 'B']  \n",
    "    medium = ['F', 'G', 'H', 'L', 'M', 'K',  'I', 'J', 'Q', 'R', 'S', 'T'] \n",
    "    low = ['C', 'D', 'E', 'N', 'O', 'P']\n",
    "\n",
    "    for col in high:\n",
    "        worksheet.column_dimensions[col].width = 30\n",
    "    for col in medium:\n",
    "        worksheet.column_dimensions[col].width = 18 \n",
    "    for col in low:\n",
    "        worksheet.column_dimensions[col].width = 12    \n",
    "\n",
    "def get_ids_and_titles(original, latest):\n",
    "    original_titles = original.iloc[7:, 2].values\n",
    "    latest_titles = latest.iloc[7:, 2].values\n",
    "    original_ids = original.iloc[7:, 7].values\n",
    "    latest_ids = latest.iloc[7:, 7].values\n",
    "    return original_titles, latest_titles, original_ids, latest_ids   \n",
    "\n",
    "def compare_stat(original, latest):\n",
    "    new_projs = {}\n",
    "    original_not_updated_projs = {}\n",
    "    original_updated_projs = {}\n",
    "    deleted_projs = {}\n",
    "\n",
    "    _, latest_titles, original_ids, latest_ids = get_ids_and_titles(original, latest)\n",
    "\n",
    "    for i, original_id in enumerate(original_ids):\n",
    "        if original_id not in latest_ids:\n",
    "            deleted_projs[original_id] = original.iloc[i + 7]\n",
    "\n",
    "    for i, latest_id in enumerate(latest_ids): \n",
    "        if latest_id in original_ids:\n",
    "            original_index = original[original.iloc[:, 7] == latest_id].index[0]\n",
    "            original_row = original.iloc[original_index]\n",
    "            latest_index = latest[latest.iloc[:, 7] == latest_id].index[0]\n",
    "            latest_row = latest.iloc[latest_index]\n",
    "            if original_row.equals(latest_row):\n",
    "                original_not_updated_projs[latest_id] = original_row\n",
    "            else:\n",
    "                original_updated_projs[latest_id] = latest_row\n",
    "\n",
    "        elif pd.isna(latest_id) or latest_id.isspace() or bool(re.search(r'[^a-zA-Z0-9\\-]', latest_id)) or latest_id == '':\n",
    "            if latest_titles[i] not in new_projs: \n",
    "                new_projs[latest_titles[i]] = latest.iloc[i + 7]\n",
    "            new_projs[latest_titles[i]] = latest.iloc[i + 7]\n",
    "        else:\n",
    "            print(f'###### ID ERROR. Id: {latest_id} Title: {latest_titles[i]} ######')                       \n",
    "\n",
    "    return new_projs, deleted_projs, original_not_updated_projs, original_updated_projs\n",
    "\n",
    "def process_files(orig_file, lat_file, output_fname):\n",
    "    original_sinc = pd.read_excel(orig_file, sheet_name=sincesht)\n",
    "    latest_sinc = pd.read_excel(lat_file, sheet_name=sincesht)\n",
    "    original_befo = pd.read_excel(orig_file, sheet_name=beforesht)\n",
    "    latest_befo = pd.read_excel(lat_file, sheet_name=beforesht)\n",
    "    original_new = pd.read_excel(orig_file, sheet_name=newsht)\n",
    "    latest_new = pd.read_excel(lat_file, sheet_name=newsht)\n",
    "\n",
    "    new_project_sinc, deleted_project_sinc, original_not_updated_projs_sinc, original_updated_projs_sinc = compare_stat(original_sinc, latest_sinc)\n",
    "    new_project_befo, deleted_project_befo, original_not_updated_projs_befo, original_updated_projs_befo = compare_stat(original_befo, latest_befo)\n",
    "    new_project_new, deleted_project_new, original_not_updated_projs_new, original_updated_projs_new = compare_stat(original_new, latest_new)\n",
    "\n",
    "    output_dir = os.path.dirname(output_fname)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    try:\n",
    "        with pd.ExcelWriter(output_fname) as writer:\n",
    "            pd.DataFrame.from_dict(new_project_sinc, orient='index').to_excel(writer, sheet_name='New Projs Since 2017')\n",
    "            pd.DataFrame.from_dict(deleted_project_sinc, orient='index').to_excel(writer, sheet_name='Deleted Projs Since 2017')\n",
    "            pd.DataFrame.from_dict(original_updated_projs_sinc, orient='index').to_excel(writer, sheet_name='Updated Projs Since 2017')\n",
    "            pd.DataFrame.from_dict(original_not_updated_projs_sinc, orient='index').to_excel(writer, sheet_name='Not Updated Projs Since 2017')\n",
    "\n",
    "            pd.DataFrame.from_dict(new_project_befo, orient='index').to_excel(writer, sheet_name='New Projs Before 2017')\n",
    "            pd.DataFrame.from_dict(deleted_project_befo, orient='index').to_excel(writer, sheet_name='Deleted Projs Before 2017')\n",
    "            pd.DataFrame.from_dict(original_updated_projs_befo, orient='index').to_excel(writer, sheet_name='Updated Projs Before 2017')\n",
    "            pd.DataFrame.from_dict(original_not_updated_projs_befo, orient='index').to_excel(writer, sheet_name='Not Updated Projs Before 2017')\n",
    "\n",
    "            pd.DataFrame.from_dict(new_project_new, orient='index').to_excel(writer, sheet_name='New Projs new')\n",
    "\n",
    "        df = pd.read_excel(output_fname, sheet_name=None)\n",
    "\n",
    "        sheets_to_exclude = []\n",
    "        for sheet in df:\n",
    "            if df[sheet].shape[1] == 0:\n",
    "                sheets_to_exclude.append(sheet)\n",
    "                continue\n",
    "            df[sheet] = df[sheet].iloc[:, 2:-1]\n",
    "            if df[sheet].shape[1] > len(cols):\n",
    "                df[sheet] = df[sheet].iloc[:, :len(cols)]\n",
    "            elif df[sheet].shape[1] < len(cols):\n",
    "                for col in cols[df[sheet].shape[1]:]:\n",
    "                    df[sheet][col] = pd.NA\n",
    "            df[sheet].columns = cols\n",
    "\n",
    "        sheets_to_merge = ['New Projs Since 2017', 'New Projs Before 2017', 'New Projs new']\n",
    "        merged_df = pd.concat([df[s] for s in sheets_to_merge if s not in sheets_to_exclude], axis=0)\n",
    "        df['New Projects'] = merged_df[cols]\n",
    "        sheets_to_exclude.extend(sheets_to_merge)\n",
    "\n",
    "        with pd.ExcelWriter(output_fname) as writer:\n",
    "            for sheet in df:\n",
    "                if sheet in sheets_to_exclude:\n",
    "                    # print(f'###### Empty Sheet {sheet} has been excluded ######')\n",
    "                    continue\n",
    "                df[sheet].to_excel(writer, sheet_name=sheet, index=False)\n",
    "                format_excel(writer, sheet)    \n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred while writing to Excel:\", e)        \n",
    "\n",
    "cols = ['SWG', 'Project Title', 'Status', 'On/Off/Treasury Budget', 'Humanitarian Aid', 'Project description', \n",
    "        'Project ID (in AMP)', 'Actual Approval Date', 'Actual Start Date', 'Actual Closure Date', \n",
    "        'Donor Group', 'Donor Agency', 'Implementing Agency', 'Type of Assistance', 'Mode of Payment', \n",
    "        'Aid Modality', 'Actual Commitments', 'Actual Disbursements', 'Undisbursed Balance']\n",
    "\n",
    "sincesht = 'Existing projects approved sinc'\n",
    "beforesht = 'Existing projects approved befo'\n",
    "newsht = 'Record new projects'\n",
    "\n",
    "file_pairs = [\n",
    "    ('ODA_Original_and_Latest/OrigHPN.xlsx', 'ODA_Original_and_Latest/LatHPN.xlsx', 'Report/HPN.xlsx'),\n",
    "    ('ODA_Original_and_Latest/OrigBSD.xlsx', 'ODA_Original_and_Latest/LatBSD.xlsx', 'Report/BSD.xlsx'),\n",
    "    ('ODA_Original_and_Latest/OrigREDFS.xlsx', 'ODA_Original_and_Latest/LatREDFS.xlsx', 'Report/REDFS.xlsx'),\n",
    "    ## Add more file pairs here\n",
    "]\n",
    "\n",
    "tqdm.write('Processing files...')\n",
    "for orig_file, lat_file, output_fname in tqdm(file_pairs):\n",
    "    process_files(orig_file, lat_file, output_fname)\n",
    "tqdm.write('Processing Done!')    \n",
    "\n",
    "\n",
    "directory = 'Report'\n",
    "excel_files = glob(os.path.join(directory, '*.xlsx'))\n",
    "merged_data = {}\n",
    "\n",
    "for file in excel_files:\n",
    "    xls = pd.ExcelFile(file)\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(file, sheet_name=sheet_name)\n",
    "        if sheet_name in merged_data:\n",
    "            merged_data[sheet_name] = pd.concat([merged_data[sheet_name], df])\n",
    "        else:\n",
    "            merged_data[sheet_name] = df\n",
    "\n",
    "with pd.ExcelWriter('Report/All.xlsx') as writer:\n",
    "    for sheet_name, data in merged_data.items():\n",
    "        data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "with pd.ExcelWriter('Report/All.xlsx') as writer:\n",
    "    for sheet in merged_data:\n",
    "        merged_data[sheet].to_excel(writer, sheet_name=sheet, index=False)\n",
    "        format_excel(writer, sheet)\n",
    "    \n",
    "merged_file_path = 'Report/All.xlsx'\n",
    "response_file_path = 'ODA_Original_and_Latest/Response.xlsx'\n",
    "output_file_path = 'Report/All_with_Response.xlsx'\n",
    "\n",
    "response_sheet = pd.read_excel(response_file_path, sheet_name='Form Responses 1')\n",
    "response_values = response_sheet[response_sheet.columns[3]].astype(str).str.strip()\n",
    "\n",
    "merged_sheets = pd.read_excel(merged_file_path, sheet_name=None)\n",
    "\n",
    "tobe_formated = None\n",
    "with pd.ExcelWriter(output_file_path) as writer:\n",
    "    for sheet_name, merged_data in merged_sheets.items():\n",
    "        merged_values = merged_data[merged_data.columns[1]].astype(str).str.strip()\n",
    "        output_rows = []\n",
    "\n",
    "        for merged_index, merged_val in merged_values.items():\n",
    "            for response_index, response_val in response_values.items():\n",
    "                if response_val.endswith('...') and response_val[:-3] in merged_val:\n",
    "                    combined_row = merged_data.loc[merged_index].to_dict()\n",
    "                    combined_row.update(response_sheet.loc[response_index].to_dict())\n",
    "                    combined_row[response_sheet.columns[3]] = merged_val\n",
    "                    output_rows.append(combined_row)\n",
    "                elif response_val == merged_val or response_val in merged_val or merged_val in response_val:\n",
    "                    combined_row = merged_data.loc[merged_index].to_dict()\n",
    "                    combined_row.update(response_sheet.loc[response_index].to_dict())\n",
    "                    output_rows.append(combined_row)\n",
    "\n",
    "        if output_rows:\n",
    "            output_df = pd.DataFrame(output_rows)\n",
    "            print(f'Found {output_df.shape[0]} matching rows in {sheet_name}')\n",
    "            output_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print('Done!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
